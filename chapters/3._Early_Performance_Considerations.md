[Previous: Chapter 2. Testing the Datatable](./chapters/2._Testing_the_Datatable.md)

# Chapter 3
## Early Performance Considerations

I am a strong advocate of no premature optimizations.  That being said I can't help but notice that the datatable is already a tad more sluggish than I would like when the data changes.  Once the data is loaded the view is responsive so I don't need to invesitgate that but I do want to see if I can figure out any optimizations for the loading of the data into the table.

For  most components this wouldn't be a concern but datatables are notorious for having efficiency problems so in this particular case I think it's worth investigating early.  I will revisit and possibly retest the methods below once the datatable is closer to completion to see if further changes provide any new information.  But at this stage I just want to get some quick and dirty checks out of the way to make sure I'm not missing anything obvious.

## Testing Methodology

This will just be a quick test to see if I can find any obvious improvements.  I don't expect anything drastic as my methods aren't particularly rigoruous but if any of the results stand out even with my methods it should be telling about overall performance.  Therefore I won't concern myself too much with getting exact timing data.  All I will do is change the `data` `Input` to a setter where I save a call to `performance.now`.

```ts
private dataCache: T[];

@Input() set data(d: T[]){
    console.log('new data');
    this.startTime = performance.now();
    this.dataCache = d;
}
```

And register the `ngAfterViewChecked` lifecycle callback where if I have a start time I do a difference with an end time from `performance.now` and set the start time to `null` to only register time slices when the data source is changed.  This quick and dirty method works when `onPush` change detection is used since currently the only part of the view that updates is the table and it only will do so when the bindings change.

```ts
ngAfterViewChecked() {
    if(this.startTime) {
        console.log('ellapsed time:', (performance.now() - this.startTime)/1000);
    }
    this.startTime = null;
}
```
## Investigating Fixes

The first potential culprit is the `getData` function.

```ts
getData(path: string, row: T) {
    return path.split('.').reduce((data,fragment)=>{
        if(data[fragment]) {
            return data[fragment];
        }
        else {
            return '';
        }
    },row);    
}
```

Here I am using a `reduce` method on the result of a `String.split` call.  While they have been showing steady performance gains as newer versions of browsers are released the functional `Array` methods are generally slower than standard looping.  So first I will try using both a standard `for` loop and also a `for of` loop to see if either of those show a noticeable difference.

The standard `for` version looks like this.
```ts
getData(path: string, row: T) {
    let data: T | T[keyof T] | string  = row;
    const paths = path.split('.');

    for(let i = 0; i < paths.length; i++) {
        if(data[paths[i]]) {
            data = data[paths[i]];
        }
        else {
            data = '';
            break;
        }
    }

    return data;
}
```

And this is the `for of` version.

```ts
getData(path: string, row: T) {
    let data: T | T[keyof T] | string  = row;

    for(let fragment of path.split('.')) {
        if(data[fragment]) {
            data = data[fragment];
        }
        else {
            data = '';
            break;
        }
    }
    return data;
}
```

For the testing I will just quickly reload the largest dataset, 300 items, 10 times and then throw out the highest and lowest outliers and average the other 8 results together.

## Results

<table>
    <thead>
        <tr>
            <th>Algorithm</th>
            <th>Time</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>`reduce`</td>
            <td>0.618s</td>
        </tr>
        <tr>
            <td>`for`</td>
            <td>0.623s</td>
        </tr>
        <tr>
            <td>`for of`</td>
            <td>0.682s</td>
        </tr>
    </tbody>
</table>

As I expected there isn't a definitive enough time difference to say for sure which of any of these 3 methods are the fastest.  I mostly attribute the differences to the weakness of my methodology.  But interestingly `for of` was enough of an outlier that I will avoid using it for this part of the component just in case it is actually noticeably slower.

Since the `reduce` version 'won' I will continue to use it unless I can find a definitive answer as to which solution would be the fastest.

In the meantime I have another idea to potentially help the performance.

## Short Circuit

Another quick optimization to look at is short circuiting the logic for walking the path to the desired value.  The test used above: 

```ts
if(data[fragment]) {
    data = data[fragment];
}
else {
    data = '';
    break;
}
```

Can be changed to the logically equivalent:

```ts
data[fragment] || ''
```

## Results

<table>
    <thead>
        <tr>
            <th>Algorithm</th>
            <th>Time</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>`if`</td>
            <td>0.618s</td>
        </tr>
        <tr>
            <td>`||`</td>
            <td>0.522s</td>
        </tr>
    </tbody>
</table>

So after making that change and using the same methodology as above the results actually do show that short circuiting makes what seems to be a noticable difference.  If nothing else the short circuited version isn't slower so for now I will go with that method.

So at this point I now have this `getData` method.

```ts
getData(path: string, row: T) {
    return path
        .split('.')
        .reduce((data,fragment)=>data[fragment] || '', row);
}
```

## Caching

Another obvious potential performance improvement is caching.  Since the component is already using `onPush` change detection I know that the `getData` method is not being called continuously to reevaluate the row data.  I might end up with some optimizations there if I determine something is necessary later but for now I will leave the data itself alone.

However inside the `getData` method is a call to `String.split` for every iteration.

```ts
return path.split('.').reduce(...)
```

The column definitions however don't change per row.  So instead I can precalculate the result of the `split` and cache those values.  A quick version gives me this code.

```ts
private c: Column[]
private columnsCache;

@Input() set columns(columns: Column[]) {
    if(this.c != columns) {
        this.columnsCache = columns.map(c=>({
            title: c.title,
            path: c.path.split('.')
        }));
        this.c = columns;
    }
}

get columns() {
    return this.columnsCache;
}

getData(path: string[], row: T) {
    return path.reduce((data,fragment)=>data[fragment] || '', row);
}
```

## Results

<table>
    <thead>
        <tr>
            <th>Algorithm</th>
            <th>Time</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>uncached columns</td>
            <td>0.569s</td>
        </tr>
        <tr>
            <td>cached columns</td>
            <td>0.568s</td>
        </tr>
    </tbody>
</table>

I'm not actually surprised by the results.  A built in `String.split` method is probably very well optimized resulting in the difference being a rounding error at best.  I would imagine that the actual difference might show itself if the number of columns defined were very large but this is definitely entering the realm of preoptimization.  So for now I will remove the caching behavior although I will keep the code around for later just in case I need to reinvestigate this case.

But with these results for now I don't see any reason to keep the caching behavior so I will just revert to the simpler columns handling.

```ts
@Input() columns: Column[];

getData(path: string, row: T) {
    return path
        .split('.')
        .reduce((data,fragment)=>data[fragment] || '', row);
}
```

I have one more plan for early optimization.  I know this will show a performance improvement.  However, it also puts a bit more burden on the developer using this datatable component.

# TrackBy

For anyone who has dealt with iterating over large lists in Angular before you should already be aware of the `trackBy` field of the `ngFor` directive.  If you aren't it basically keys the rows so that Angular can determine if a particular entry is being reused and if so it can optimize the path so that it doesn't have to rerender the result of the iteration every time.

I fully expect `trackBy` to make a very large and noticeable difference when used.  My only slight concern here is what `trackBy` will do when it isn't in use.

I have added in `trackBy` methods for both the row and column iterations.  When testing this I only included the `trackBy` method that was under test and completely removed the statements not being used.  In theory a `null` check somewhere inside `ngIf` should incur a very small cost but I want to try and isolate my testing as much as possible.  Again, these tests aren't meant to be a canonical study of the performance but even for just very rough estimates I still want to use some amount of rigor.

In order to facilitate `Column` tracking I created a new type for internal use of the component that extends the existing `Column` definition and adds in a new `id` field.  This `id` can be used in the `trackBy` method and a simple mapping operation on the `Input` can seemlessly add these `id`s in without changing the outward API of the datatable.

```ts
private trackedColumns: TrackedColumn[];
private columnsId = 0;

@Input() set columns(columns: Column[]) {
    this.trackedColumns = columns.map(c=>({
        ...c,
        id: this.columnsId++
    }));
}

get columns() {
    return this.trackedColumns;
}

columnTracker: TrackByFunction<TrackedColumn> = 
    (index: number, column: TrackedColumn) => column.id;
```

For the row tracking I need a default `trackBy` method in case the user doesn't supply one.  Just returning the row itself should suffice for now at least.

```ts
@Input() rowTracker: TrackByFunction<T> = (index: number, row: T)=>row;
```

Finally, since my testing data set already includes an `_id` field I will create a method in the component that creates the table and pass it down on the `Input` bindings for the test cases that call for it.

```ts
idTracker = (index: number, row: Entry)=>row._id;
```

```html
<table app-datatable
    [data]="data$ | async"
    [columns]="columns"
    [rowTracker]="idTracker">
```

# Results

<table>
    <thead>
        <tr>
            <th>Algorithm</th>
            <th>Time</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>No Tracking</td>
            <td>0.563s</td>
        </tr>
        <tr>
            <td>Columns Tracking</td>
            <td>0.567s</td>
        </tr>
        <tr>
            <td>Row Tracking Default</td>
            <td>0.566s</td>
        </tr>
        <tr>
            <td>Row Tracking Input</td>
            <td>0.369s</td>
        </tr>
        <tr>
            <td>Both Tracking</td>
            <td>0.378s</td>
        </tr>
    </tbody>
</table>

The difference beetween the columns being tracked or not is negligible which makes sense as the columns are a very small dataset compared to the size of the rows.

Tracking the rows however makes a very noticeable difference.  In this particular instance I had to toggle data sets as the timing when just refreshing the same data was so low it was irrelevant.  Some of the datasets were shared though which is I believe where the performance gains are coming from.

The results show that if at least some of the data stays the same as the entire data set changes that the gains from the rows `trackBy` are too big to ignore.  The columns `trackBy` are minimal at best in this case however for now I will leave the column tracking in as well.  Near the end of this development process I will try the columns testing again using a much wider data set to see if it is ever noticable but in the mean time it doesn't appear to have any negative consequences for the component.

Now that I am done with the testing I will move the code used for it out of the component.  However, I will keep copies of it so that I don't have to reimplement it again later if it is needed.

## Wrap Up

So after a good bit of investigation I have determined that most of my ideas weren't worthwhile.  The end result of all this is short circuiting an if statement and implementing `trackBy`, which is something I was planning on doing anyway.

The biggest lesson is I just proved to myself again that premature optimization isn't particularly useful.  However, despite my potential optimizations turning out to be useless I at least developed a methodology and some testing code to help in the future in case I do run into real performance issues.

Finally, the biggest take away from all this for me is that any time you are dealing with large data sets, if at all possible, I should absolutely use `trackBy` functions.  In the worst case scenario they are a negligible hit to performance and in the best case scenarios they drastically descrease the time to render.

I might not have accomplished much but I feel like I am well prepared for future development with everything I have learned doing all this.

[Previous: Chapter 2. Testing the Datatable](./chapters/2._Testing_the_Datatable.md)
